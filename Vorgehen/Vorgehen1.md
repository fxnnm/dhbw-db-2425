### ğŸš¦Â Vorgehensplan fÃ¼r **SchrittÂ 3 â€“Â Datenâ€‘Import & â€‘Bereinigung**

**Ausgangslage**

- Das relationale Schema ist bereits Ã¼ber `create_table.sql` in MySQL angelegt.  
- Rohdaten liegen imâ€¯`data/`â€‘Ordner als einzelneâ€¯CSVâ€‘/JSONâ€‘Dateien (z.â€¯B. `01_fahrzeug.csv`, `unfall.json`) vorâ€¯îˆ€citeîˆ‚turn4file0îˆ.  
- Lautâ€¯`TODO.md`â€¯mÃ¼ssen **alle** Imports in Transaktionen laufen und es kann eine Datenbereinigung nÃ¶tig seinâ€¯îˆ€citeîˆ‚turn4file2îˆ.  

---

#### 1â€¯|â€¯Vorbereitung

1. **QuellÂ­dateien inventarisieren**  
   - Liste aller CSV/JSON/XLSXâ€‘Dateien anlegen (Dateiname, Inhalt, vermutete Zieltabelle).  
2. **Mappingâ€‘Tabelle erstellen**  
   - Spalteâ€‘zuâ€‘Spalteâ€‘Zuordnung zwischen QuellÂ­datei und MySQLâ€‘Tabelle inklusive Datentypâ€‘Umwandlungen (Datumâ€¯â†’â€¯`DATE`, Dezimaltrennzeichenâ€¯â†’â€¯`DECIMAL(â€¦)`, Boolescheâ€¯WerteÂ u.â€¯s.â€¯w.).  
3. **Importâ€‘Reihenfolge festlegen**  
   - EntitÃ¤ten ohneâ€¯FKs zuerst â†’ danach abhÃ¤ngige Tabellen.  
   - Typische Reihenfolge im Telematikâ€‘Modell:  
     `fahrzeug` â†’ `fahrer` â†’â€¯`geraet` â†’â€¯`geraet_installation` â†’â€¯`fahrt` â†’â€¯`messwert` â†’â€¯`wartung` etc.  

## ğŸ“ŒÂ Mappingâ€‘TabelleÂ (CSVÂ â‡¢Â MySQL)

| Reihenfolge | CSVâ€‘Datei | MySQLâ€‘Tabelle |
|-----------|------------------------|----------------------|
|Â 1 | 01_fahrzeug.csv | fahrzeug |
|Â 2 | 02_fahrer.csv | fahrer |
|Â 3 | 03_fahrer_fahrzeug.csv | fahrer_fahrzeug |
|Â 4 | 04_geraet.csv | geraet |
|Â 5 | 05_fahrt.csv | fahrt |
|Â 6 | 06_fahrt_fahrer.csv | fahrt_fahrer |
|Â 7 | 07_fahrzeugparameter.csv | fahrzeugparameter |
|Â 8 | 08_beschleunigung.csv | beschleunigung |
|Â 9 | 09_diagnose.csv | diagnose |
|Â 10 | 10_wartung.csv | wartung |
|Â 11 | 11_geraet_installation.csv | geraet_installation |

*(Die Reihenfolge orientiert sich an der FKâ€‘AbhÃ¤ngigkeit und eignet sich fÃ¼r den Importâ€‘Workflow.)*

### ğŸ“¥Â Importâ€‘Reihenfolge (CSVÂ â†’Â MySQL)

1. **01_fahrzeug.csv**Â â†’Â `fahrzeug`  
2. **02_fahrer.csv**Â â†’Â `fahrer`  
3. **03_fahrer_fahrzeug.csv**Â â†’Â `fahrer_fahrzeug`  
4. **04_geraet.csv**Â â†’Â `geraet`  
5. **05_fahrt.csv**Â â†’Â `fahrt`  
6. **06_fahrt_fahrer.csv**Â â†’Â `fahrt_fahrer`  
7. **07_fahrzeugparameter.csv**Â â†’Â `fahrzeugparameter`  
8. **08_beschleunigung.csv**Â â†’Â `beschleunigung`  
9. **09_diagnose.csv**Â â†’Â `diagnose`  
10. **10_wartung.csv**Â â†’Â `wartung`  
11. **11_geraet_installation.csv**Â â†’Â `geraet_installation`


---

#### 2â€¯|â€¯Staging & Bereinigung

| Schritt | Warum? | Wie? |
|---------|--------|------|
| **Stagingâ€‘Tabellen** | Rohdaten unverÃ¤ndert einspielen, spÃ¤tere Reâ€‘Imports mÃ¶glich | 1â€‘zuâ€‘1â€¯Kopie der Zieltabelle ohneâ€¯FKs/PKs (`*_stg`). |
| **Constraints deaktivieren** | Import beschleunigen | `SET FOREIGN_KEY_CHECKS=0;` |
| **Datenbereinigung** | Dubletten, Nullâ€‘Werte, Formate | SQLâ€‘`UPDATE`/`DELETE`, z.â€¯B. vereinheitlichte Kennzeichen, Trim/Upper, rangeâ€‘Checks fÃ¼r Messwerte |
| **Validierung** | QualitÃ¤t sicherstellen | SQLâ€‘Assertions/SELECTâ€‘Checks, z.â€¯B. â€keine Fahrten ohne Fahrerâ€œ |

---

#### 3â€¯|â€¯Importâ€‘Skriptâ€Skeleton (MySQL)

```sql
-- file: 03_import_data.sql
START TRANSACTION;

-- 1. Fahrzeug
LOAD DATA LOCAL INFILE 'data/01_fahrzeug.csv'
INTO TABLE fahrzeug_stg
FIELDS TERMINATED BY ';'
ENCLOSED BY '"'
IGNORE 1 ROWS
(id, kennzeichen, hersteller, baujahr);

-- Bereinigung Beispiel
UPDATE fahrzeug_stg
SET  kennzeichen = UPPER(TRIM(kennzeichen));

-- Ãœbertrag in Zieltabelle
INSERT INTO fahrzeug(id, kennzeichen, hersteller, baujahr)
SELECT DISTINCT id, kennzeichen, hersteller, baujahr
FROM fahrzeug_stg
ON DUPLICATE KEY UPDATE
  kennzeichen = VALUES(kennzeichen),
  hersteller  = VALUES(hersteller),
  baujahr     = VALUES(baujahr);

-- 2. Weitere Tabellen analoge BlÃ¶cke â€¦
-- â€¦

COMMIT;
```

**Fehlerbehandlung**  
- Innerhalb jedes Blocks `DECLARE EXIT HANDLER FOR SQLEXCEPTION`â€¯â†’â€¯`ROLLBACK;`.  
- Skript abbrechen, Protokoll in eigener `import_log`â€‘Tabelle speichern (Datei, Zeile, Fehler).

---

#### 4â€¯|â€¯Werkzeuge & BestÂ Practices

| Tool | Zweck |
|------|-------|
| `LOAD DATA INFILE` oder `mysqlsh \importTable` | Schnellster Bulkâ€‘Import fÃ¼r CSV |
| `jq` / `mysqlsh util.importJSON` | JSON â†’ Tabelle |
| TransaktionsgrÃ¶ÃŸe | Bei Millionen Zeilen ggf. **Batching** (`COMMIT` nachâ€¯50â€¯k) |
| Indexâ€‘Handling | SekundÃ¤rÂ­indizes erst **nach** dem Import anlegen |
| Zeitâ€‘Stempel | Spalten `created_at`, `import_batch_id` fÃ¼r Nachvollziehbarkeit |

---

#### 5â€¯|â€¯IntegritÃ¤tsâ€‘ und Plausiâ€‘Checks

- **Rowâ€‘Counts**: Stagingâ€‘Zeilen = Zielâ€‘Zeilen (erwartete Items)  
- **FKâ€‘Beziehungen**: `SELECT â€¦ LEFT JOIN â€¦ WHERE child.fk IS NULL` â†’â€¯0â€¯Ergebnisse.  
- **DomÃ¤nenprÃ¼fungen**: z.â€¯B. Geschwindigkeit 0â€“300â€¯km/h, Temperatur â€“40â€¯â€“â€¯+150â€¯Â°C.  

---

#### 6â€¯|â€¯Dokumentation

1. **README Abschnitt â€Importâ€œ**:  
   - benÃ¶tigte MySQLâ€‘Option (`local_infile=1`)  
   - Aufrufbeispiel: `mysql < 03_import_data.sql`  
2. **Mappingâ€‘Tabelle & Bereinigungsregeln** als Markdown (`docs/import_mapping.md`).  
3. **Importâ€‘Log**: Jeder Lauf erzeugt Eintrag in `import_log` (Datei, Zeilen, Dauer, Erfolg).

---

#### 7â€¯|â€¯NÃ¤chste Schritte nach erfolgreichem Import

- TriggerÂ &â€¯StoredÂ Procedures (Changelogâ€‘Trigger, â€Neueâ€¯Fahrtâ€œ-SP).  
- Mongoâ€‘Konvertierung (Teilâ€¯2).  
- Reports 1â€‘3 als vorbereitete Views oder gespeicherte Statements.

---

**Kurz gesagt**:  
1. **Stagingâ€‘Tabellen nutzen**, 2. **Rohdaten laden**, 3. **in einer einzigen Transaktion bereinigenâ€¯&â€¯Ã¼berfÃ¼hren**, 4. **validieren**â€¯â€“ alles sauber skriptgesteuert und versioniert. Damit ist der Datenimport reproduzierbar, fehlertolerant und erfÃ¼llt die Anforderungen aus derâ€¯`TODO.md`.